\chapter{Chapter Two}\label{chap:Two}
%一个用于直播电商监管的营销行为特征库
%\textsf{Marketing behavior Feature Banks for Live Streaming E\-commerce Supervision}

参阅论文\textsf{Long-Term Feature Banks for Detailed Video Understanding}
\href{https://github.com/Henry-sun1974/ucasthesis}{\texttt{ucasthesis}} 
\href{https://github.com/facebookresearch/video-long-term-feature-banks}{\texttt{参阅论文}}

\section*{摘要} 
为了更好地理解直播电商视频中营销事件，需要将视频正在发生的行为与过去联系起来，并将营销事件置于上下文中。
在本节中，为了使现有的视频模型也能做到这一点，借鉴长期特征库的思想，提出一个直播电商营销行为长期库，
利用过去直播电商视频监管过程中提取的支持信息，以增强当前最先进的视频模型，有效弥补这些模型只能查看5秒以内的短片。
实验表明，使用长期特征库增强 3D 卷积网络可以在四个具有挑战性的视频数据集上产生最先进的结果：AVA、EPIC-Kitchens 
和 Charades，并在现有的直播电商监管数据集上达到81.7\%。

\section{引言}
\subsection{Motivation}
直播电商监管的关键是如何识别视频中的营销事件，由于营销事件是个典型的复杂事件，因此要想正确、快速识别这些事件，这需要将视频现在发生的事情与过去发生的事情联系起来。 如果没有利用过去来理解现在的能力，作为监管人员，是无法理解我们正在监管的内容。

\subsection{Relative Work}
长期以来，计算机视觉研究中使用 ImageNet 预训练网络从孤立的帧中提取特征，然后将这些特征用作训练池或循环网络的输入，
这些相同的特征既反映当前的背景，也表达了长期信息。
[Long-term Feature Bank ]通过使用预先计算的视觉特征来利用长期时间信息这一理念[25, 31, 45, 57]，提出了一个长期特征库的想法，
该特征库存储整个视频的丰富的时间索引表示，将过去和可用的未来场景、对象和动作的信息进行编码并存储形成长期特征库。
这些信息支持上下文内容，允许视频模型（例如 3D 卷积网络）更好地推断当前正在发生的事情。
现有的实验证明，该长期特征库能够改进最先进的视频模型，克服了大多数预测仅基于来自短视频剪辑信息的不足，
有效解决3D卷积端到端网络必须密集采样才能有效工作和视频输入片段较短的问题。
同时将当前信息与长期信息解耦，将长期特征库视为增强标准视频模型的辅助组件，例如最先进的 3D CNN。 这种设计使长期特征库能够存储灵活的支持信息，例如与 3D CNN 计算的不同的对象检测特征。

\subsection{Our Approach}
本节借鉴长期特征库思想，提出了一个基于直播电商监管营销行为特征库。
在实践应用中，这个营销行为特征库可与 3D CNN 简单集成起来。
实验证明了多种机制是可行的，包括一种注意力机制，它将关于当前的信息（来自 3D CNN）与存储在长期特征库中的远程信息相关联。
在对象级以及帧或视频级预测的数据集上结果表明，这个特征库可在具有不同输出要求的不同任务中得以应用。
最后，大量的实验说明，使用营销行为特征库增强 3D CNN 在直播电商监管视频视频数据集上产生了最先进的结果。
消融研究也表明，这些任务的改进源于长期信息的整合。

本节结构如下：

\begin{enumerate}
    \item 第2节介绍了相关的工作。

    \item 第3节介绍了营销行为特征模型

%下载 \href{https://github.com/mohuangrui/ucasthesis}{ucasthesis} 模板并解压。ucasthesis模板不仅提供了相应的类文件，同时也提供了包括参考文献等在内的完成学位论文的一切要素，所以，下载时，推荐下载整个ucasthesis文件夹，而不是单独的文档类。
    \item 第4节在直播电商监管数据集上的试验
        \begin{enumerate}
            \item 实现细节
            \item 消融实验
        \end{enumerate}
    \item 第5节介绍了与SOTA比较
    %请先查看“常见问题”（章节~\ref{sec:qa}）。
    \item 最后小结。
\end{enumerate}

\section{相关工作}

\subsection{深度神经网络 Deep networks}

深度神经网络是视频理解的主要方法[5、21、33、39、46-48、50、51、56]。
既有应用广泛的双流网络[21,39,50]和3D卷积网络[5,33,46-48,51,56]。
在本节采用3D CNN，但营销行为特征库也可以与其它的视频模型很方便地集成使用。

\subsection{时间关系模型 Temporal and relationship models}

时间关系模型包括建模视频帧演化的RNN[7,24,27,44,57]和建模有序帧特征[58]的多层感知器（MLP）。
为了建模更细粒度的交互，越来越多的工作线利用预先计算的对象提取[52]或检测[4,30]，
并在一个短片段内对它们的共现[30,43,52]、时间顺序[4]或空间排列[52]进行建模。

\subsection{长期视频理解 Long-term video Understanding }

目前,CNN对长期视频理解研究较少，已知部分原因是由于硬件的限制，如GPU内存。
现有的研究表明，使用预先计算的特征是克服这些限制的一个有效办法，端到端训练[25,31,45,57]还需要关键的突破。
但由于这些方法并不能优化目标任务的特征，因此结果仅可能是次优的。
另一种方法是使用aggressive subsampling[50,58]或大大步[8]。TSN[50]采样每段视频3-7帧。
ST-ResNet[8]使用的时间步幅为15。
本文采取端到端学习strong短期特征、密集采样和灵活解耦，以及灵活的长期建模，据现有的实验表明，本文采取的方法是最优的。

\subsection{时空行为定位 Temporal action localization}

时空动作定位是当前计算机视觉领域的一个研究热点[12,14,17,32,40,53]。
最近的研究进展是扩展了对象检测框架[10,34]，首先在短剪辑/框架中提出管/盒子，然后将管/盒子分类为动作类[14,17,20,32,36,36]。
检测到的管/盒可以选择连接形成完整的作用管[12,17,20,32,36,40]。
这些方法可以在每一帧或剪辑中独立地找到动作，而不需要利用长期的上下文。
而[Long-term feature bank]使用的方法与上相反。

\subsection{信息库 Information bank}

已知的对象库[26]、检测库[1]和存储器网络[42]等信息特征库表示，已在图像级广泛使用，在视频索引和检索、文本语料库中的信息建模等得到积极应用。
本节从上述方法中获得灵感，为具体的视频理解任务探索简单而又方便的方法。

\section{直播电商营销行为特征库模型}

现有的计算机视觉模型表明，要想对长而复杂的视频做出准确的预测，必须将当前发生的事情与时间上遥远的事件联系起来。
具体对直播电商监管来说，营销活动是一个复杂事件，要想对长而复杂的营销活动做出准确的识别，必须考虑直播电商营销行为长期特征。
针对这一想法，本文提出了一个带有长期特性库的直播电商营销行为特征库模型，以实现长期视频理解进程中的交互。

\subsection{方法概述}
本节描述了如何用于时空行动定位任务的方法，目标之一是检测视频中的网络主播，并对他们的行为进行分类。
以前大多数最先进的方法[9,14,43]是把一个“主干”的3DCNN(例如，C3D[46]，I3D[5])与一个基于区域的人探测器(例如，Fast/Faster R-CNN[10,34])结合起来。
为了处理一个视频，它被分成2-5秒的短片，通过3DCNN独立转发计算一个特征图，然后与区域建议和感兴趣区域(RoI)池一起计算每个候选参与者[9,14]的RoI特征。
这种方法仅能捕获短期信息，如图3a所示。

本节使用的方法，在long-term feature bank上加以扩展应用：
（1）长期特征库。直观地作为整个视频中发生的事情的“记忆”，将计算定期采样时间步长的RoI特征；
（2）是一个特征库操作符(FBO)，它计算短期行为特征（描述参与者现在正在做什么）和长期特征之间的交互。
（3）交互可以通过注意机制计算，如非局部块[51]，或通过特征池和连接。我们的模型总结在图3b中。
下面，将详细介绍这个办法。

\subsection{直播电商营销行为特征库}
直播电商营销行为特征库，L，目的是提供相关的上下文信息，以实现在当前的时间步长中进行行为识别。
当用于时空动作定位的任务，如具体营销行为时，需要在整个视频上运行一个网络主播行为的探测器，为每一帧生成一组检测。
同时，运行一个标准的基于剪辑的3DCNN，如C3D[46]或I3D[5]，在视频上以有规则的间隔间隔，比如每一秒一次。
然后我们使用RoI池来提取使用3D CNN 处理的每个时间步对所有人的检测特征。
形式上，L=[L0，L1，...，LT−1]是视频时间步长0，...，T−1的时间索引特征列表，其中Lt∈RNt×是时间t×维RoI特征的矩阵。
直观地说，L提供了关于整个视频中所有人员在何时以及做什么的信息，并且可以通过探测器和 3D CNN 通过视频一次来有效地计算出来。

\subsection{直播电商营销行为特征操作}

本节提出的模型，通过营销行为特征操作符FBO(St，˜Lt)引用了来自长期特征L的信息。
特征库操作符接受输入圣˜Lt，圣是短期投资回报率汇集特性和˜Lt[Lt−w，...，Lt+w]，L的一个子集集中在当前剪辑在t窗口大小2w+1，堆积成矩阵˜Lt∈RN×d，N=t+wtwtwNt。
我们将窗口大小2w+1作为一个我们在实验中交叉验证的超参数。
然后，输出通过通道与St连接，并用作线性分类器的输入。
直观地说，特征银行操作符通过将其与长期特征联系起来，计算出合并的短期特征St的更新版本。
FBO的实现是灵活的。
注意机制的变体是一个明显的选择，我们将在实验中考虑多个实例。

\subsection{实现细节}

\subsubsection{主干}
我们使用了一个标准的3D CNN 架构作为主干。
该模型是一个ResNet-50[16]，在ImageNet[35]上进行预训练，并使用I3D技术[5]“扩展”成一个具有3D卷积（超过空间和时间）的网络。
网络结构被修改为包括非局部操作[51]。
在将网络从二维扩展到三维后，我们在动力学-400数据集[5]上进行视频分类的预训练。该模型在动力学-400[5]验证集上达到了74.9\%（91.6\%）的前1名（前5名）的精度。
最后，我们在[52]之后删除了conv1和pool1的时间步进，并删除了特定于动力学的分类层，以生成主干模型。确切的模型规格详见补充材料。
所得到的网络接受形状为32×H×W×3的输入，代表32个具有H×W空间大小的RGB帧，并输出形状为16×H/16×W/16×2048的特征。
相同的体系结构用于计算短期特征S和长期特征l。
除非另有说明，否则参数在这两个模型之间不共享。

\subsubsection{RoI池}
本文首先在时间轴上对视频主干特征进行平均池。
然后，我们使用空间输出为7×7的 RoIAlign[15]，然后使用空间最大池化，为RoI生成一个单一的2048维特征向量。
这相当于使用一个时间直管[14]。

\subsubsection{使用}
直播电商营销行为特征操作安装。可通过多种方式来使用直播电商营销行为特征库的操作。
– LFB NL：我们的默认特征库算子 FBONL(St,L~t) 是注意力算子。
直观地说，我们使用 St 来关注 L~t 中的特征，并通过快捷连接将关注的信息添加回 St。
我们使用一个简单的实现，其中 FBONL(St,L~t) 是最多三个非局部 (NL) 块的堆栈[51]。
我们用局部特征 St 和长期特征窗口 L~t 之间的注意力替换标准非局部块 [51] 的自注意力。
此外，我们的设计使用层归一化（LN）[3]和dropout [41]来改进正则化。
由于我们的目标任务包含相对较少的训练视频，在训练时容易表现出过度拟合，因此使用正则化修改对于实际应用非常重要。
修改后的堆栈，其中 θ{1,2,... } 是可学习的参数。 
类似于王等人[52]，我们使用线性层将 FBONL 输入维度降低到 512，并以 0.2 的速率应用 dropout [41]。
因此最终线性分类器的输入是 2048 (St) 512 (FBONL 输出) = 2560 维。

\subsubsection{训练}
由于通过长期特征库进行反向传播的计算和内存复杂性，对整个模型的端到端联合训练(图3b)是不可行的。
相反，我们将用于计算L的3DCNN和检测器视为固定组件，它们离线训练，但仍然在目标数据集上，随后不会更新。
我们实验了交替优化方法来更新这些模型，类似于目标传播[23]，但发现它们并没有改善结果。
稍后将给出特定于数据集的培训细节。

\subsubsection{短期操作基准}
为了验证合并长期信息的好处，此外，我们还研究了该模型的“退化”版本。
相反，它使用了一个与FBONL相同的短期操作符，但只引用了来自剪辑中的信息：STO(St)：=FBONL(St，St)。
STO在概念上类似于[52]，并允许反向传播。我们观察到与STO的大量过拟合，因此应用了额外的正则化技术。详见补充资料。

\section{实验}

本文使用AVA数据集[14]进行广泛的消融研究。AVA由235个训练视频和64个验证视频组成；每个视频都是一个15分钟的视频片段。
帧以1FPS稀疏地标记。标签是：框中每个人周围的一个边界框，以及一个多标签注释，指定框中的人在标记帧的±0.5秒内从事哪些操作。
操作标签空间被定义为由数据集作者定义的80个“原子”操作。
AVA中的任务是时空动作定位：出现在测试视频中的每个人都必须在测试视频的每一帧中被检测到，并且必须正确预测被检测到的人的多标签动作。
算法的质量是由一个平均平均精度(mAP)度量来判断的，该度量需要至少50\%的联合(IoU)重叠的交集，以使检测与地面真相相匹配，同时预测正确的操作。

\subsection{实现细节}

接下来，我们将描述了用于AVA的对象检测器、输入采样以及训练和推理细节。

\subsubsection{网络主播检测}
本文使用Faster R-CNN[34]和ResNeXt-101-FPN[28,55] 作为主干来进行网络主播的检测。
该模型在ImageneNet[35]和COCO关键点[29]上进行预训练，然后在AVA边界框上进行微调；训练细节见补充材料。
最终的模型在AVA验证集上获得93.9AP@50。

\subsubsection{时间采样}
短期和长期特征都是由 3D CNN 提取的，使用32帧采样，时间步幅跨越63帧(30FPS视频中∼2秒)。
长期特征在整个视频中以每秒一个剪辑的速度计算，并在AVA上对3DCNN模型(图3a)进行了微调。

\subsubsection{训练}

实验中使用同步SGD来训练现有的模型，在8个GPU上使用16个剪辑(即每个GPU 2个剪辑)，与批标准化[18]层冻结。
对所有模型进行了140k次迭代的训练，学习率为0.04，在迭代100k和120k时降低了10倍。
权重衰减为10^−6，动量为0.9。
对于数据增强，执行随机翻转、随机缩放、使短边像素，和大小为224∈[256,320]×224的随机裁剪。
我们使用地面真实框和得分至少为0.9的预测框进行训练。这就解释了地面真盒分布和预测盒分布之间的差异，我们发现它是有益的。
如果一个地面真实盒的标签与IoU至少0.9重叠，我们将其分配给一个预测框。
一个预测的方框可能没有分配任何标签。由于长期特征的数量N因剪辑而不同，我们为具有较少长期特征的剪辑填充零向量，以简化小批量训练。

\subsubsection{推理}

在测试时，我们使用≥0.85的检测。
所有模型都将短边重新缩放到256像素，并使用单中心裁剪256×256。
对于训练和推理，如果一个框跨越裁剪边界，我们将裁剪剪辑中的区域池。
在罕见的情况下，一个盒子掉出裁剪区域，RoIAlign[15]在边界处汇集该特征。

\subsection{消融实验}

\section{其它数据集上的表现}
\subsection{在 AVA 数据集上}
\subsection{在EPIC-Kitchens 数据集上}
\subsection{在Charades 数据集上}

\section{讨论}

图6显示了使用不同窗口大小的LFB的相对增益。我们看到不同的数据集表现出不同的特征。
视频数据集AVA得益于持续2+分钟的非常长的上下文。
实现对直播电商的监管，正确识别直播电商营销行为是必要的，而且识别15至60秒的上下文内容，甚至更长时间的营销活动内容尤其重要。
Charades 视频要短得多（∼为30秒），但将时间支持扩展到10+秒仍然是有益的。
可以预见，未来更具挑战性的数据集可能会受益更多。

综上所述，为了更好地识别直播电商视频中的营销行为，我们提出了一个用于为视频模型提供长期支持性信息的直播电商营销行为长期特征库。
我们展示了，通过LFB使视频模型能够访问长期信息，可以带来巨大的性能提高，并在AVA、EPIC-Kicchens 和 Charades 等具有挑战性的数据集上产生最先进的结果。
