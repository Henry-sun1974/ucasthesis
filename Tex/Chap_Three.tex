\chapter{MSL-VID-2019数据集:基于直播电商监管业务视频数据集构建}\label{chap:Three}

摘要 直播电商进入爆发期，给监管工作带来颠覆性压力，如何加强直播电商监管成为全国各级监管部门的紧迫性课题。
直播电商主要以视频的形式为载体，但具有区别于传统视频的特性。
虽然目前对视频研究的数据集不少，但鲜有直播电商的视频数据集来支持。
本文介绍了我们在研究直播电商监管业务时构建的视频数据集：
MSL-VID-2019数据集在当前版本中，MSL-VID-2019提供了203个活动类的样本，平均每个类137个未修剪的视频，每个视频1.41个活动实例，总共849个视频小时，旨在研究如何解决电商直播视频实际场景下的识别问题。


\section{引言}
数字经济扑面而来，直播电商进入爆发期，作为新业态在成为当前经济发展的亮点的同时，给政府监管部门带来了新的课题，也给监管工作带来颠覆性压力。
如何加强直播电商监管成为全国各级监管部门的紧迫性课题。
电商是直播视频流量变现的理想场景，直播电商的载体主要是直播视频，因此加强对直播电商的直播视频进行研究成为当前监管的关键。

随着直播电商用户和活动增长，直播电商视频数据库的数量和规模都在以令人难以置信的速度增长。
尽管视频数据的爆炸式增长，但自动识别和理解电商网络交易行为活动的能力仍然相当有限。
对现有的监管人员来说，阻碍当前技术性能研究的一个重要限制，是存在的视频数据集问题，即缺乏可以解决电商直播视频实际场景下的视频数据集和研究标准。
现有的数据库往往是具体的，并专注于有限类型的活动。

本文构建了一个数据集MSL-VID-2019。该数据集围绕一个直播电商营销语义本体构建，语义本体根据电商平台直播营销行为来指导组织活动。它具有至少三个深度层次的结构，是一个在丰富的语义分类下组织的直播电商网络交易行为识别数据库。

本文组织结构如下：首先，我们回顾和总结了现有的直播电商网络营销的标准。然后，详细介绍了我们收集的数据集和标注的细节，并提供了对MSL-VID-2019的属性的总括。

\section{相关工作}
在过去的十几年里，各国学者提出了最具影响力的行动数据集。
\subsection{最初的视频数据集}}
如Hollywood dataset[20]包含了取自好莱坞电影的视频，由12个动作类别由专业演员执行，这比早期的简单动作数据集[33,9]产生更自然的场景。
类似地，UCF Sports数据集[30]和Olympic Sports数据集[24]通过关注高度清晰的体育活动，增加了动作的复杂性。
但是，类别的数量较少，使得活动的范围较窄。
复杂性的另一个维度是由关注可组合[21]和并发[41]活动的数据集来解决的，但这些活动受到场景和环境假设的约束。

\subsection{UCF101[17]-Thumos 14[35]和HMDB51[19]数据集}
这些数据集由YouTube视频编译，有50多个动作类别。
所得到的视频样本很短，而且只传达了简单的短期行动或事件。
这些视频是通过手工和昂贵的过程收集的，如果要扩展数据集的大小，就很难进行缩放。
在语义组织方面，HMDB51将活动分为5种主要类型：一般面部、与物体操作的面部、一般身体运动、与物体互动的身体运动和与人体互动的身体运动。
另一方面，UCF101将类别分为5类：人物互动、身体运动、演奏乐器、运动。
不足的是，这些是简单的分类，只有两个级别的解决，没有提供详细的活动事件。

\subsection{MPII人体姿态数据集[2]}
专注于人体姿态估计，最近被应用于动作识别[29]。
它提供了描绘人类行为的短片段（41帧或更长的时间）。
不足的是，每个类别的视频样本的分布是不均匀的，且偏向于某些行动类别。

目前，可用的最大的视频数据集是Sports-1M数据集[16]，大约有500个体育相关类别，由自动标记算法注释。
尽管该数据集规模庞大，但该数据集使用了一些有限的活动分类法，因为它只关注体育行为。
此外，自动收集过程引入了一个未公开量的标签噪声。

与我们的工作相关的还有努力为静态图像中的对象识别构建大尺度的基准。
诸如ImageNet[5]、SUN[42]和TinyImages[36]等图像基准测试已经在计算机视觉算法的相关任务中取得了重大进展。
大规模视觉识别挑战(ILSVRC)[32]就是一个例子，AlexNet架构[18]由于在挑战中的出色表现而广受到欢迎。

\subsection{ActivityNet}
涵盖了与人类如何在日常生活中花费时间最相关的活动；
每个视频的数量和长度（而不是短片段）、活动分类的多样性和类的数量的定性跳跃；
与全自动注释算法相比，人的循环注释过程可以提供更高的标签精度；
以及一个低成本连续数据集扩展的框架。

\subsection{Kinetics} 人体动作视频数据集。该数据集包含400个人体动作类，每个动作至少有400个视频剪辑。
每个片段持续约10秒，取自YouTube，包含了大量的行为特征，但行为较为简单。

综上所述，大多数视频数据集关注的模态特征有限，对人类行为的涉及简单，数据规模较短，没有可以针对解决多模态人物行为识别问题。

本文介绍的MSL-VID-2019数据集，是用于多模态电商直播视频识别的大规模数据集。
与表 1.1 中列举了一些当期流行的数据集进行对比可知，这是一个当前最大的多模态电商直播视频监管数据集。
其总时长超过 5230 小时，共计70 多万个视频。该数据集是从广泛类型的实际电商平台在线视频中提取的视频片段。
然后，监管人员用人工注释标记了少部分剪辑，并采用自动算法以加快收集和标记过程。
首先从庞大的长视频数据集中提取视频剪辑。然后，通过自动算法过滤掉没有人或多人的剪辑。
最后，按照身份对候选片段进行分组，然后将其放入手动注释中。

\section{MSL-VID-2019电商直播视频介绍}

MSL-VID-2019数据集的目的是提供一个描述直播电商网络交易行为视频的语义组织。
在本节中，我们将介绍作为 MSL-VID-2019的主干的定义电商直播营销的行为词典和层次结构。然后介绍了电商直播视频的收集和标注。

\subsection{直播电商营销的行为字典}

MSL-VID-2019 数据集是用于多模态直播电商营销行为识别的大规模数据集。
电子商务是基于网络交易语义的一种行为，我们基于分类法的基础上构建 MSL-VID-2019数据集。
我们依据《电子商务参与方分类与编码》(中国物品编码中心, 北京交通大学 et al. 2016)和
《电子商务信用　网络交易信用主体分类》(中国标准化研究院, 深圳市众信电子商务交易保障促进中心 et al. 2015)国家标准，
对层次结构提供的4000多个活动示例中手动选择了203个活动类别的子集。活动类属于2个不同的顶级类别，9个二级类别，
我们还准备将数据集用分类法刻画四个粒度级别，它构成了一个语义组织主干，在模型训练期间将对利用层次结构的算法中有很大的好处。

\subsection{直播电商视频收集和预处理}

根据国家市场监管总局37号令《网络交易监督管理办法》（以下简称《办法》），
直播服务提供者需将网络交易活动的直播视频自直播结束之日起至少保存三年，
网络交易新业态的经营者需以显著方式展示商品或者服务及其实际经营主体、售后服务等信息，充分保障消费者的知情权，
县级以上地方市场监督管理部门应当在日常管理和执法活动中监管部门对直播服务提供者开展监督检查、案件调查、事故处置、
缺陷消费品召回、消费争议处理，并实施信用监管。视频集来自全国市场监管部门在日常监管、抽检监测、定向监测和双随机抽查过程中
对监管的主要19个直播电商平台保存内容的采样。
(国家市场监督管理总局网络商品交易监督管理司 2021.3)
这些电商直播视频剪辑是依据《直播营销管理规定》，按照电商直播电商平台监管规定和要求，由监管人员在日常监督检查中获得的。
从全国各地区现有电商直播视频平台中大量的在线视频中提取的。

为了使数据集更接近真实情况，该数据集是从广泛类型的真实在线视频中提取的视频片段。
然后，监管人员用人工注释标记了部分剪辑监管分类标注，并采用自动算法以加快收集和标记过程，该操作的流程图如图 1.5 所示。
首先从庞大的长视频数据集中提取视频剪辑。然后，通过自动算法过滤掉没有人或多人的剪辑。
之后，按照身份对候选片段进行分组，然后将其放入手动注释中。

\subsubsection{提取视频片段}

原始视频是市场监管部门从电商直播视频数据库提取得，涵盖电商直播营销的等各个方面。
根据连续帧之间的差异，每个原始视频将被分割为多个镜头。短于3秒钟的视频剪辑会从数据集中排除，因为它们通常缺少多模态信息。
本文取CNN作为电商直播视频输入的一个原始框架，并将其传递给卷积层来理解直播视频状态。
由于直播电商视频原始帧将有210x160像素和128色的调色板，如果采取直接输入原始像素的方法，会耗费的大量的无法承担的计算和内存。
在试验环境中，我们采取像素降维到84x84，同时将RGB值转换为灰度值。
采取这样预处理后，我们把电商直播视频素材作为卷积层的输入。
我们使用两个卷积层，然后是一个以ReLU作为激活函数的全连接层。
在这里，我们不使用池化层。当我们执行对象检测或分类等任务时，池化层的作用至关重要，
其中我们不考虑对象在图像中的位置，只要确定所需的对象在图像中即可。

\subsubsection{通过头部检测自动过滤和主播身份获取候选剪辑}

作为识别人员的标准，每个视频剪辑都必须包含一个且只有一个主要人物。
为了找出主要人物，使用 YOLO V2 算法可检测到头部区域。
有效帧定义为这一帧画面中仅检测到一个头像区域的帧，或者最大头像区域的面积比其他头像区域的面积大三倍的帧。
有效片段定义为有效帧超过 30\%的比例的片段。不包含有效帧的剪辑被称为无效的剪辑，将被删除。
但是，由于头部检测器无法检测到所有头部，因此在此阶段可以保留一些片段。一些噪声片段将在手动过滤步骤中被丢弃。
对包含有多个人的视频剪辑片段会使数据集更接近实际应用程序，但这也大大识别和标注的难度，在实际应用加以剪切。
该视频剪辑包含来自人脸识别数据库的 3253 个主播身份标识的标签。
在此阶段，每个剪辑都将通过人脸识别标记一个初始身份，初始身份均是从网络监管的主播数据库中选取。
面部由 SSH 模型[13]检测，然后再由 Arc Face[3]模型识别，并对营销活动标注行为标签。

\subsubsection{噪声检测和过滤}

在导入的视频中反复用双流动作分类器[19]来识别这些噪声。
将检测到的混淆来合并、分割或完全删除。
在收集了所有数据、删除重复数据后，最后的手动剪辑过滤阶段，使用双流模型的类进行打分，分数排列最低的即是噪声。
同时可利用排列找到毗邻的类余的重复视频，并过滤掉那些视频。
	
\subsubsection{手动标注监管目标分类}

约30\%剪辑片段都通过手动注释过程，针对监管职责的分工要求，对监管类别进行标注。
后续将针对监管类目进行标注。通过数据清理后，系统还会随机选择了 10％的数据集进行质量测试，数据标签错误率保持在 0.2％以内。

\subsubsection{数据统计} 
该 MSL-VID-2019 数据集包含了 65万个视频片段，整个数据集由｛图像，主播，商品名称，监管分类｝四元组组成，主播姓名由短语组成，
商品名称和监管分类来自相应字典编码，图像是base64编码的JPEG图像缩略图，监管分类由人工标注，大约有1.2万左右。
整个数据集被划分为三个部分，数据集的 40\%用作训练集，数据集的 30\％用做验证集，剩下的 30\％视频剪辑用于测试集。
训练集有 260568 个视频，验证集有195426个视频，测试集有195426个视频，总计 470个不同营销场景。
通过把该数据集和其他数据集进行对比，发现该数据集视频数目多，营销行为种类多，识别难度大。
\begin{table}[!htbp]
    \bicaption{不同数据集性能比较}{Compairison of video datasets.}
    \label{tab:比较}
    \centering
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.2}%row space 
    \begin{tabular}{lccccc}
        \hline
        Dataset	& Year &	Actions	Clips &	Total &	Videos \\
        %\cline{2-9}% partial hline from column i to column j
        \hline \hline
        HMDB-51 [15] & 2011 & 51 & min102 & 6266 & 3312 \\
        UCF-101 & 2012 & 101 & min101 &13320 & 2500 \\
        ActivityNet-200 & 2015 & 200 &avg101 & 28108 \\
        Kinetics & 2017 & 400 & min400 & 306245 & 306245 \\
        MSL-VID-2019 & 2019 & 470 & min619 & 572391 & 651420 \\
        \hline
    \end{tabular}
\end{table}
    



\section{试验}
\subsection{评价指标}

为了准确评价实验中所用方法提取倒的特征的质量，需要将它们输入到分类器中进行判别。
分类结果的评价标准可以用来评价特征的性能。其评价标准用Mean Average Precision(m AP)。
具体表达如下公式所示.

\subsection{行为检测}

行为检测是应用有关的算法从视频开始帧到结束帧，计算出在视频中出现的每个活动的持续时间。
为了评估不同的分类模型，我们利用MSL-VID-2019的部分标注实施评估，从而形成电商直播营销活动视频数据集。
数据集：我们将现有视频数据集与ActivityNet数据集和Kinetics数据集进行了对比。在跨模态视频数据集中，我们取得较好的分数。
请见表~\ref{tab:比较}。
\begin{table}[!htbp]
    \bicaption{不同数据集性能比较}{Compairison of video datasets.}
    \label{tab:比较}
    \centering
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.2}%row space 
    \begin{tabular}{lccc}
        \hline
        数据集名称 & 方法 &性能}\\
        %\cline{2-9}% partial hline from column i to column j
        \hline
        ActivityNet数据集 & 15 & 22.9\%\\
        Kinetics数据集 & 18 & 37.1\%\\
        MSL-VID-2019 & 16 & 40.4\%\\
        \hline
    \end{tabular}
\end{table}

分类器：我们使用在修剪后的活动分类任务中学习到的分类器来初始化我们的SVM模型。
然后，我们采用五轮硬负挖掘，为每个活动类生成一组负样本。
在每一轮之后，我们只保持最困难的缺点，以保持一个合理的运行时间。
给定一个测试视频序列，我们使用滑动时间窗口方法应用学习到的分类器。
在训练视频时，我们发现通常存在7个时间窗口长度：25、60、78、100、150、190和250帧。然后，我们固定了一个100帧的滑动步长。
最后，我们执行非最大抑制来忽略重叠的检测窗口。

结果：为了衡量我们的模型的性能，我们计算了所有行为类的mAP分数。
检测结果表明，在不同的值下，MF始终优于DF和SF。
尽管DF和SF的性能也不高，但模型显示，当所有特征类型组合时，性能显著提高。试验数据表明，当前的数据集基本满足后续任务的需要。
请见表~\ref{tab:性能评价}
\begin{table}[!htbp]
    \bicaption{性能评价}{Preferences evalute.}
    \label{tab:性能评价}
    \centering
    \footnotesize %fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \begin{{tabular}{lccccc}
        \hline
        特征 & \alpha=0.1 	& \aleph=0.2	&\alpha=0.3	& \alpha=0.4	&\alpha=0.5\\
        MFI	& 12.1\% & 9.3\% & 3.9\%	& 10.7\%  &7.1\% \\
        DFI & 3.9\%	&10.1\% &5.0\% & 3.3\%	& 9.8\% \\
        SFI & 4.3\% & 3.0\%	& 8.9\% & 3.9\% & 2.1\% \\
        MF+DF+SF	& 12.3\%	& 11.6\%	& 11.0\%	&10.3\%	&9.5\% \\
表2 性能评价

\section{结论}

本文基于直播电商监管业务的需要，构建了一个直播电商监管业务视频数据集MSL-VID-2019。
该数据集围绕直播电商营销语义本体构建，语义本体围绕电商平台营销行为来指导组织活动。
它具有至少三个深度层次的结构，是一个在丰富的语义分类下组织的直播电商网络交易行为识别数据库。


国家市场监督管理总局网络商品交易监督管理司 (2021.3). "《网络交易监督管理办法》学习读本."
	
中国标准化研究院, et al. (2015). 电子商务信用　网络交易信用主体分类, 中华人民共和国国家质量监督检验检疫总局;中国国家标准化管理委员会. GB/T 31951-2015: 8.
	
中国物品编码中心, et al. (2016). 电子商务参与方分类与编码, 中华人民共和国国家质量监督检验检疫总局;中国国家标准化管理委员会. GB/T 32875-2016: 8.
	




本文研究分析了一个名叫 MSL-VID-2019（Market Supvision in Livestreaming_E-commerace Video Dateset）[51]的数据集。通过研究数据集，旨在研究如何解决电商直播视频实际场景下的识别问题。并且在表 1.1 视频识别数据库中列出了一些当下流行的数据集。
大多数视频数据集仅关注一种模态特征，即脸部[11,12],全身或音频。据表 1.1 所知，没有大规模的数据集是可以针对解决多模态人物识别问题。
本文介绍了MSL-VID-2019数据集，MSL-VID-2019数据集是用于多模态电商直播视频识别的大规模数据集。与表 1.1 中列举了一些当期流行的数据集进行对比可知，这是一个当前最大的多模态电商直播视频监管数据集。其总时长超过 5230 小时，共计70 多万个视频。该数据集是从广泛类型的实际电商平台在线视频中提取的视频片段。然后，监管人员用人工注释标记了少部分剪辑，并采用自动算法以加快收集和标记过程。首先从庞大的长视频数据集中提取视频剪辑。然后，通过自动算法过滤掉没有人或多人的剪辑。最后，按照身份对候选片段进行分组，然后将其放入手动注释中，详细信息如下：

试验环境由大数据中心4台并行服务器与24个NVDIA Tesla K80双GPU构成的加速计算平台，采用Tensorflow框架，优化函数选择Adam Optimizer，损失函数以交叉熵SoftMax函数作为依据。

